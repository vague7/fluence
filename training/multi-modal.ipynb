{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7b26f4",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/how_to/multimodal_inputs/#documents-from-a-url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8340ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "925dab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f31135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", )\n",
    "# response = model.invoke(\"Hello World!!\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736be79",
   "metadata": {},
   "source": [
    "Gemini models are intelligent enough to take multimodal input with longer context window. This solves lot of problems and somehow elimintaes the need for RAG (not completely if its query intensive.) Here we just summarize the content once so RAG is not needed as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d649cec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ज़रूर, मैं आपकी मदद कर सकता हूँ। यहाँ स्रोत का सारांश दिया गया है:\n",
      "\n",
      "यह पॉडकास्ट चोल साम्राज्य के बारे में बात करता है, जो लगभग 9वीं शताब्दी से 13वीं शताब्दी तक सत्ता में रहा और जिसने दक्षिण भारत को एक शक्तिशाली और समृद्ध साम्राज्य बनाया। उनका साम्राज्य तमिलनाडु से लेकर श्रीलंका और मालदीव तक फैला हुआ था।\n",
      "\n",
      "चोल राजाओं ने एक मजबूत नौसेना बनाई जिसके कारण वे समुद्री व्यापार में भी आगे रहे। चोल साम्राज्य की सबसे खास बात थी उनका स्थानीय स्वशासन। उन्होंने गांवों में उर और सभा जैसी संस्थाएं बनाईं जो गांव के मामलों को खुद देखती थीं। इसके अलावा, चोल राजाओं ने कला और साहित्य को भी बहुत बढ़ावा दिया। उन्होंने बड़े-बड़े मंदिर बनवाए, जैसे कि तंजावुर का बृहदेश्वर मंदिर, जो आज भी उनकी महानता की कहानी कहता है।\n",
      "\n",
      "चोल साम्राज्य के राजाओं में राजाराज चोल प्रथम और राजेंद्र चोल प्रथम सबसे प्रसिद्ध थे। राजाराज चोल प्रथम ने नौसेना की शक्ति का इस्तेमाल करके कई देशों को जीता, जबकि राजेंद्र चोल प्रथम ने गंगा नदी तक अपनी सेना भेजी और गंगैकोंड चोलपुरम नामक नई राजधानी बनाई।\n",
      "\n",
      "लेकिन 13वीं शताब्दी में पांड्य राजाओं के आक्रमणों के कारण चोल साम्राज्य कमजोर हो गया और धीरे-धीरे खत्म हो गया।\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Using ChatPromptTemplate for multimodal input\n",
    "def create_multimodal_template():\n",
    "    \"\"\"Create a ChatPromptTemplate that can handle multimodal input\"\"\"\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an educational AI assistant. Analyze images/pdf and provide detailed explanations suitable for students.\"),\n",
    "        (\"human\", [\n",
    "            {\"type\": \"text\", \"text\": \"{text_input}\"},\n",
    "            # {\"type\": \"image_url\", \"image_url\": {\"url\": \"{image_url}\"}}\n",
    "            {\"type\": \"file\", \"url\": \"{file_url}\", \"source_type\": \"url\"}\n",
    "\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "    return template\n",
    "\n",
    "text_input = \"Describe this image\"\n",
    "image_url = ''\n",
    "\n",
    "# Usage with template\n",
    "multimodal_template = create_multimodal_template()\n",
    "\n",
    "pdf_url = 'https://kclenjtsvdayeghmmmkm.supabase.co/storage/v1/object/public/learning-sources/public/Slides_Module8.pdf'\n",
    "image_url = 'https://kclenjtsvdayeghmmmkm.supabase.co/storage/v1/object/public/learning-sources/public/maxresdefault.jpg'\n",
    "audio_url = 'https://kclenjtsvdayeghmmmkm.supabase.co/storage/v1/object/public/learning-sources/public/speech_20250704112803322.mp3'\n",
    "\n",
    "# Format the prompt\n",
    "formatted_prompt = multimodal_template.format_messages(\n",
    "    text_input=\"Summarise the content in the provided source\",\n",
    "    # image_url=\"\"  # or base64 URL\n",
    "    # file_url=image_url  # or base64 URL\n",
    "    file_url=audio_url\n",
    ")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0ec48",
   "metadata": {},
   "source": [
    "## Building a multi-modal assistance for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2feaa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student profile type definition\n",
    "class StudentProfile(TypedDict):\n",
    "    gender: str\n",
    "    class_level: str  # e.g., \"class 6\", \"12th\", \"undergrad\", \"postgrad\"\n",
    "    language: str     # e.g., \"hindi\", \"english\", \"marathi\"\n",
    "\n",
    "\n",
    "class UserPrompt(TypedDict):\n",
    "    topic: str\n",
    "    file_url: str\n",
    "    # image_file: str\n",
    "    # audio_file: str\n",
    "\n",
    "# Graph state\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    student_profile: StudentProfile\n",
    "    user_prompt: UserPrompt\n",
    "    summary_notes: str\n",
    "    podcast_script: str\n",
    "    mindmap: str\n",
    "    quiz: str\n",
    "    recommended_resources: str\n",
    "    study_plan: str\n",
    "    combined_output: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03789c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts Templates\n",
    "class PersonalizedPromptsStudent:\n",
    "    def __init__(self, topic, file_url: str, student_profile: dict, user_instructions: str = \"\"):\n",
    "        self.topic = topic\n",
    "        self.file_url = file_url\n",
    "        self.student_profile = student_profile\n",
    "        self.user_instructions = user_instructions\n",
    "\n",
    "    def summary_notes(self):\n",
    "        \"\"\"Create a personalized prompt based on student profile\"\"\"\n",
    "\n",
    "        template = ChatPromptTemplate([\n",
    "            (\"system\", \"\"\"You are an expert academic tutor. Create personalized educational content following these guidelines:\n",
    "            \n",
    "            Student Profile:\n",
    "            - Class Level: {class_level}\n",
    "            - Language: {language} \n",
    "            - Gender: {gender}\n",
    "            \n",
    "            Content Requirements:\n",
    "            1. Use the audio/image/pdf if provided by the user\n",
    "            2. Concise Summary notes\n",
    "            3. Use bullet points and simple language appropriate for {class_level}\n",
    "            4. Include practical examples and analogies\n",
    "            5. Make it engaging and easy to understand\n",
    "            6. If language is not English, provide content in {language}\n",
    "            \n",
    "            Additional Instructions: {user_instructions}\"\"\"),\n",
    "\n",
    "            # (\"user\", \"Please teach me about: {topic}\"),\n",
    "            \n",
    "            (\"human\", [\n",
    "                {\"type\": \"text\", \"text\": \"Topic {topic}\"},\n",
    "                {\"type\": \"file\", \"url\": \"{file_url}\", \"source_type\": \"url\"}\n",
    "\n",
    "            ])\n",
    "        ])\n",
    "\n",
    "        return template.invoke({\n",
    "            \"topic\": self.topic,\n",
    "            \"class_level\": self.student_profile.get(\"class_level\", \"general\"),\n",
    "            \"language\": self.student_profile.get(\"language\", \"English\"),\n",
    "            \"gender\": self.student_profile.get(\"gender\", \"\"),\n",
    "            # \"word_limit\": \"150\",\n",
    "            \"user_instructions\": self.user_instructions or \"Focus on key concepts with examples\",\n",
    "            \"file_url\": self.file_url\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a459c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_summary_notes(state: State):\n",
    "    \"\"\"LLM call to generate summary notes for student\"\"\"\n",
    "\n",
    "    summary_prompt_template = PersonalizedPromptsStudent(\n",
    "        state['user_prompt']['topic'], state['user_prompt']['file_url'], state['student_profile'])\n",
    "\n",
    "    summary_prompt = summary_prompt_template.summary_notes()\n",
    "\n",
    "    msg = model.invoke(summary_prompt)\n",
    "\n",
    "    return {\"summary_notes\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd77a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state = {\n",
    "    \"student_profile\": {\n",
    "        \"gender\": \"MALE\",\n",
    "        \"class_level\": \"12th\",\n",
    "        \"language\": \"HINDI\"\n",
    "    },\n",
    "    \"user_prompt\": {\n",
    "        \"topic\": \"Uncertainty in AI\",\n",
    "        \"file_url\": \"https://kclenjtsvdayeghmmmkm.supabase.co/storage/v1/object/public/learning-sources/public/Slides_Module8.pdf\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23079577",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = node_summary_notes(input_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738bc70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_notes': \"ज़रूर, यहाँ आपके लिए AI में अनिश्चितता (Uncertainty) पर नोट्स दिए गए हैं:\\n\\n**AI में अनिश्चितता (Uncertainty in AI)**\\n\\nअनिश्चितता का मतलब है कि AI सिस्टम को हमेशा यह नहीं पता होता है कि क्या हो रहा है या आगे क्या होगा। इसे मापने और संभालने के तरीके यहाँ दिए गए हैं:\\n\\n**1. अनिश्चितता में काम करना (Acting under Uncertainty)**\\n   - AI एजेंटों को अनिश्चित स्थितियों से निपटना होता है।\\n   - एजेंट कभी भी निश्चित नहीं हो सकते कि वे किस स्थिति में हैं या कार्यों के बाद कहाँ पहुँचेंगे।\\n   - एजेंट 'बिलीफ स्टेट' को ट्रैक करके अनिश्चितता को संभालते हैं।\\n\\n   *उदाहरण:*\\n   - एक ऑटोमेटेड टैक्सी को हवाई अड्डे पर समय पर एक यात्री को पहुँचाना है, लेकिन उसे ट्रैफिक या अन्य अप्रत्याशित देरी का सामना करना पड़ सकता है।\\n\\n**2. बुनियादी संभाव्यता नोटेशन (Basic Probability Notation)**\\n   - संभाव्यता (Probability) का उपयोग अनिश्चितता को स्पष्ट और सटीक रूप से व्यक्त करने के लिए किया जाता है।\\n   - यह जटिल मॉडल बनाने और गणनाओं को सरल बनाने में मदद करता है।\\n\\n**3. फुल जॉइंट डिस्ट्रीब्यूशन का उपयोग करके अनुमान (Inference Using Full Joint Distributions)**\\n   - संभाव्य अनुमान (Probabilistic inference) अनिश्चितता में निर्णय लेने और तर्क करने की प्रक्रिया है।\\n   - इसमें संभाव्यता सिद्धांत (Probability theory) से सिद्धांतों का उपयोग करके विश्वासों को अपडेट करना शामिल है।\\n\\n   *उदाहरण:*\\n   - यदि किसी मरीज को दाँत में दर्द है, तो यह अनुमान लगाना कि उसे कैविटी (Cavity) है या नहीं।\\n\\n**4. स्वतंत्रता (Independence)**\\n   - स्वतंत्रता का मतलब है कि एक घटना का परिणाम दूसरी घटना को प्रभावित नहीं करता है।\\n   - यह संयुक्त वितरण (Joint distribution) को सरल बनाने में मदद करता है।\\n\\n   *उदाहरण:*\\n   - मौसम (Weather) और दाँतों की समस्याएँ स्वतंत्र हैं; मौसम का आपके दाँतों पर कोई सीधा प्रभाव नहीं पड़ता।\\n\\n**5. बेज़ का नियम और इसका उपयोग (Bayes' Rule and Its Use)**\\n   - बेज़ का नियम (Bayes' Rule) संभाव्यता अनुमान (Probabilistic inference) के लिए एक महत्वपूर्ण उपकरण है।\\n   - यह हमें नई जानकारी के आधार पर विश्वासों को अपडेट करने की अनुमति देता है।\\n\\n   *सूत्र:*\\n     - P(H|E) = [P(E|H) * P(H)] / P(E)\\n       - P(H|E): परिकल्पना H की पश्च संभाव्यता (Posterior probability), साक्ष्य E को देखते हुए।\\n       - P(E|H): साक्ष्य E को देखने की संभावना, अगर H सत्य है।\\n       - P(H): परिकल्पना H की पूर्व संभाव्यता (Prior probability)।\\n       - P(E): साक्ष्य E को देखने की सीमांत संभाव्यता (Marginal probability)।\\n\\n   *उदाहरण:*\\n   - स्पैम फ़िल्टरिंग (Spam filtering): ईमेल को स्पैम के रूप में पहचानने के लिए बेज़ के नियम का उपयोग करना।\\n\\n**सारांश (Summary)**\\n   - अनिश्चितता को संभालना AI सिस्टम के लिए महत्वपूर्ण है।\\n   - संभाव्यता सिद्धांत (Probability theory) अनिश्चितता को मापने और तर्क करने के लिए एक शक्तिशाली उपकरण है।\\n   - बेज़ का नियम (Bayes' Rule) हमें नई जानकारी के आधार पर अपने विश्वासों को अपडेट करने में मदद करता है।\\n\\nमुझे उम्मीद है कि ये नोट्स आपकी मदद करेंगे! यदि आपके कोई और प्रश्न हैं तो बेझिझक पूछें।\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
